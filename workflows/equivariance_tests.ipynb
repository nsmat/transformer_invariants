{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric as tg\n",
    "\n",
    "import torch\n",
    "import e3nn\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "from models.attention_mechanisms import Se3AttentionHead, Se3EquivariantAttentionMechanism\n",
    "from utils.load_md17 import load_md17\n",
    "from utils.transforms import EuclideanInformationTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dd = load_md17('aspirin CCSD', './../real_datasets/MD17', 2)\n",
    "data = dd['train']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def make_3d_rotation_matrix(alpha, beta, gamma):\n",
    "    rot_z = torch.tensor([[torch.cos(alpha), -torch.sin(alpha), 0],\n",
    "                          [torch.sin(alpha),  torch.cos(alpha), 0],\n",
    "                          [0,                0,                1]])\n",
    "\n",
    "    rot_y = torch.tensor([[torch.cos(beta), 0, torch.sin(beta)],\n",
    "                          [0,               1,               0],\n",
    "                          [-torch.sin(beta),0, torch.cos(beta)]])\n",
    "    rot_x = torch.tensor([[1, 0,                0               ],\n",
    "                          [0, torch.cos(gamma), -torch.sin(beta)],\n",
    "                          [0 ,torch.sin(gamma), torch.cos(gamma)]]\n",
    "                         )\n",
    "\n",
    "    full_rotation_matrix = rot_z @ rot_y @ rot_x\n",
    "\n",
    "    return full_rotation_matrix\n",
    "\n",
    "\n",
    "def rotate_graph(graph: tg.data.Data, alpha, beta, gamma):\n",
    "    \"\"\"Return a copy of the graph with all geometric quantities rotated\n",
    "    according to the spherical angles alpha, beta, gamma\"\"\"\n",
    "\n",
    "    out_graph = graph.clone()\n",
    "    rotation_matrix = make_3d_rotation_matrix(alpha, beta, gamma)\n",
    "\n",
    "    out_graph.pos =(rotation_matrix @ out_graph.pos.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "    # Rederive the relative positions etc\n",
    "    transform = EuclideanInformationTransform()\n",
    "    out_graph = transform(out_graph)\n",
    "\n",
    "    return out_graph\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "graph = data[0]\n",
    "alpha, beta, gamma = map(torch.tensor, (np.pi/2., 0, 0))\n",
    "rot = make_3d_rotation_matrix(alpha, beta, gamma)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-05T09:02:45.386987200Z",
     "start_time": "2023-08-05T09:02:45.266157800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niksm\\Documents\\CodeForUni\\venvs\\transformer_invariants\\lib\\site-packages\\torch\\jit\\_check.py:181: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\"The TorchScript type system doesn't support \"\n"
     ]
    }
   ],
   "source": [
    "feature_irreps = e3nn.o3.Irreps(\"10x0e+10x1e+10x2e\")\n",
    "geometric_irreps = e3nn.o3.Irreps(\"3x0e+3x1e+3x2e\")\n",
    "output_irreps = e3nn.o3.Irreps(\"10x0e+10x1e+10x2e\")\n",
    "\n",
    "att_head = Se3AttentionHead(\n",
    "                       num_attention_layers=3,\n",
    "                       feature_input_repr = feature_irreps,\n",
    "                       feature_output_repr=feature_irreps,\n",
    "                       geometric_repr=geometric_irreps,\n",
    "                       hidden_feature_repr=feature_irreps,\n",
    "                       key_and_query_irreps=feature_irreps\n",
    "                       )\n",
    "\n",
    "att = Se3EquivariantAttentionMechanism(feature_irreps,\n",
    "                                       geometric_irreps,\n",
    "                                       output_irreps,\n",
    "                                       feature_irreps)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-05T09:02:46.665614500Z",
     "start_time": "2023-08-05T09:02:45.387988600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(att.key_network.irreps_in1 == feature_irreps)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-05T09:04:12.140912300Z",
     "start_time": "2023-08-05T09:04:12.123199100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(att.key_network.irreps_in2 == geometric_irreps)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-05T09:04:31.721157900Z",
     "start_time": "2023-08-05T09:04:31.692368200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"<eval_with_key>.61\", line 15, in forward\n    getitem_2 = getattr_3[slice(None, -1, None)];  getattr_3 = None\n    expand_2 = empty.expand(getitem_2);  empty = getitem_2 = None\n    broadcast_tensors = torch.functional.broadcast_tensors(expand, expand_1, expand_2);  expand = expand_1 = expand_2 = None\n                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n    getitem_3 = broadcast_tensors[0];  broadcast_tensors = None\n    getattr_4 = getitem_3.shape;  getitem_3 = None\nRuntimeError: The size of tensor a (9) must match the size of tensor b (50) at non-singleton dimension 1\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 10\u001B[0m\n\u001B[0;32m      2\u001B[0m features \u001B[38;5;241m=\u001B[39m embed(graph\u001B[38;5;241m.\u001B[39mz)\n\u001B[0;32m      4\u001B[0m relative_positions \u001B[38;5;241m=\u001B[39m e3nn\u001B[38;5;241m.\u001B[39mo3\u001B[38;5;241m.\u001B[39mspherical_harmonics(geometric_irreps,\n\u001B[0;32m      5\u001B[0m                                                  graph\u001B[38;5;241m.\u001B[39mrelative_positions,\n\u001B[0;32m      6\u001B[0m                                                  normalize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m      7\u001B[0m                                                  )\n\u001B[1;32m---> 10\u001B[0m \u001B[43matt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgraph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrelative_positions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m            \u001B[49m\u001B[43mgraph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistances\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munsqueeze\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\CodeForUni\\transformer_invariants\\models\\attention_mechanisms.py:38\u001B[0m, in \u001B[0;36mSe3EquivariantAttentionMechanism.forward\u001B[1;34m(self, edge_index, node_features, edge_features, distances)\u001B[0m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, edge_index, node_features, edge_features, distances):\n\u001B[1;32m---> 38\u001B[0m     k \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkey_network\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnode_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdistances\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     39\u001B[0m     q \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mquery_network(node_features)\n\u001B[0;32m     40\u001B[0m     v \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalue_network(node_features, edge_features, distances)\n",
      "File \u001B[1;32m~\\Documents\\CodeForUni\\venvs\\transformer_invariants\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\Documents\\CodeForUni\\transformer_invariants\\models\\tensor_field_networks.py:57\u001B[0m, in \u001B[0;36mRadiallyParamaterisedTensorProduct.forward\u001B[1;34m(self, feature_spherical_harmonics, geometric_spherical_harmonics, norm)\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;124;03mApplies a tensor product, paramaterised by the norm, between vectors of spherical\u001B[39;00m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;124;03m    harmonic coefficients representing features, one the one hand, and and\u001B[39;00m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;124;03m    spherical harmonics representing geometric information on the other.\u001B[39;00m\n\u001B[0;32m     54\u001B[0m \n\u001B[0;32m     55\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     56\u001B[0m weights \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mradial_net(norm)  \u001B[38;5;66;03m# Obtain the weights as a function of the norm\u001B[39;00m\n\u001B[1;32m---> 57\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor_product\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeature_spherical_harmonics\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     58\u001B[0m \u001B[43m                             \u001B[49m\u001B[43mgeometric_spherical_harmonics\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     59\u001B[0m \u001B[43m                             \u001B[49m\u001B[43mweights\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "File \u001B[1;32m~\\Documents\\CodeForUni\\venvs\\transformer_invariants\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\Documents\\CodeForUni\\venvs\\transformer_invariants\\lib\\site-packages\\e3nn\\o3\\_tensor_product\\_tensor_product.py:542\u001B[0m, in \u001B[0;36mTensorProduct.forward\u001B[1;34m(self, x, y, weight)\u001B[0m\n\u001B[0;32m    540\u001B[0m \u001B[38;5;66;03m# - PROFILER - with torch.autograd.profiler.record_function(self._profiling_str):\u001B[39;00m\n\u001B[0;32m    541\u001B[0m real_weight \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_weights(weight)\n\u001B[1;32m--> 542\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compiled_main_left_right\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreal_weight\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\CodeForUni\\venvs\\transformer_invariants\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "\u001B[1;31mRuntimeError\u001B[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"<eval_with_key>.61\", line 15, in forward\n    getitem_2 = getattr_3[slice(None, -1, None)];  getattr_3 = None\n    expand_2 = empty.expand(getitem_2);  empty = getitem_2 = None\n    broadcast_tensors = torch.functional.broadcast_tensors(expand, expand_1, expand_2);  expand = expand_1 = expand_2 = None\n                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n    getitem_3 = broadcast_tensors[0];  broadcast_tensors = None\n    getattr_4 = getitem_3.shape;  getitem_3 = None\nRuntimeError: The size of tensor a (9) must match the size of tensor b (50) at non-singleton dimension 1\n"
     ]
    }
   ],
   "source": [
    "embed = torch.nn.Embedding(graph.z.shape[1], feature_irreps.dim)\n",
    "features = embed(graph.z)\n",
    "\n",
    "relative_positions = e3nn.o3.spherical_harmonics(geometric_irreps,\n",
    "                                                 graph.relative_positions,\n",
    "                                                 normalize=True\n",
    "                                                 )\n",
    "\n",
    "att.forward(graph.edge_index,\n",
    "            features,\n",
    "            relative_positions,\n",
    "            graph.distances.unsqueeze(-1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-05T09:02:48.141196Z",
     "start_time": "2023-08-05T09:02:46.666571400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We need to create a test graph and associate node/edge features to it\n",
    "\n",
    "g = nx.DiGraph()\n",
    "vertices = np.arange(4)\n",
    "edges = [(0, 1),\n",
    "         (1, 2),\n",
    "         (2, 1),\n",
    "         (2, 3)]\n",
    "\n",
    "for v in vertices:\n",
    "    g.add_node(v)\n",
    "\n",
    "for e in edges:\n",
    "    g.add_edge(e)\n",
    "\n",
    "node_features = {0: {'z': 0, 'x': [0, 0]},\n",
    "                 1: {'z': 0, 'x': [0, 0]}}\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We need to add batch dimensions\n",
    "random_features = feature_irreps.randn(1, -1).unsqueeze(0)\n",
    "random_geometric = geometric_irreps.randn(1, -1).unsqueeze(0)\n",
    "\n",
    "distances = torch.tensor(1.).unsqueeze(0).unsqueeze(0)  # Add a batch dimension and a node dimension\n",
    "\n",
    "output = att.forward(random_features, random_geometric, distances)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_equivariance(rptp, 100, feature_irreps, geometric_irreps)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer_invariants",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
