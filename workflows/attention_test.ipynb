{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "import numpy as np\n",
    "\n",
    "from utils.transforms import EuclideanInformationTransform, OneHot\n",
    "from  models.se3_attention_mechanisms import Se3AttentionMechanism\n",
    "from models.se3_equivariant_transformer import Se3EquivariantTransformer\n",
    "\n",
    "import e3nn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Let's test the SE3 equivariant version of the GAT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "g = nx.DiGraph()\n",
    "\n",
    "vertices = (0, 1, 2)\n",
    "edges = [(0, 1),\n",
    "         (1, 0),\n",
    "         (1, 2),\n",
    "         (2, 0),\n",
    "         ]\n",
    "\n",
    "z = [0, 1, 2,]\n",
    "pos = [(0.,   0.,  0.),\n",
    "       (-1., -1., -1.),\n",
    "       (1.,   1.,  1.),\n",
    "     ]\n",
    "\n",
    "features = {i: {'z': z[i], 'pos': pos[i]} for i in vertices }\n",
    "\n",
    "for v in vertices:\n",
    "    g.add_node(v)\n",
    "\n",
    "for e in edges:\n",
    "    g.add_edge(*e)\n",
    "\n",
    "nx.set_node_attributes(g, features)\n",
    "\n",
    "graph = tg.utils.from_networkx(g)\n",
    "\n",
    "euc_transform = EuclideanInformationTransform()\n",
    "one_hot_transform = OneHot('z', 'z')\n",
    "transform = tg.transforms.Compose([euc_transform, one_hot_transform])\n",
    "\n",
    "graph = transform(graph)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niksm\\Documents\\CodeForUni\\venvs\\transformer_invariants\\lib\\site-packages\\torch_geometric\\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = tg.data.DataLoader([graph, graph.clone()], batch_size=1)\n",
    "for batch in test_dataloader:\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niksm\\Documents\\CodeForUni\\venvs\\transformer_invariants\\lib\\site-packages\\torch\\jit\\_check.py:181: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\"The TorchScript type system doesn't support \"\n"
     ]
    }
   ],
   "source": [
    "feature_irreps = e3nn.o3.Irreps(\"5x0e\")\n",
    "geometric_irreps = e3nn.o3.Irreps(\"3x0e+3x1e\")\n",
    "output_irreps = e3nn.o3.Irreps(\"10x0e + 10x1e\")\n",
    "internal_key_query_irreps = e3nn.o3.Irreps(\"5x0e+5x1e\")\n",
    "\n",
    "num_attention_heads = 2\n",
    "net = Se3EquivariantTransformer(\n",
    "    num_features=graph.z.shape[1],\n",
    "    num_attention_layers=4,\n",
    "    num_feature_channels=10,\n",
    "    num_attention_heads=num_attention_heads,\n",
    "    feature_output_repr=output_irreps,\n",
    "    geometric_repr=geometric_irreps,\n",
    "    hidden_feature_repr=feature_irreps,\n",
    "    key_and_query_irreps=internal_key_query_irreps,\n",
    "    radial_network_hidden_units=5,\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from tests.test_attention_mechanism_equivariance import GraphInputEquivarianceTest\n",
    "alpha, beta, gamma = e3nn.o3.rand_angles(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# For normal inputs\n",
    "output = net.forward(graph=graph\n",
    "           )\n",
    "\n",
    "final_output_irreps = (output_irreps*num_attention_heads).simplify()\n",
    "rotation_matrix_for_output = final_output_irreps.D_from_angles(alpha, beta, gamma).squeeze(0)\n",
    "rotated_output = output @ rotation_matrix_for_output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "rotated_graph = graph.clone()\n",
    "\n",
    "position_rotator = e3nn.o3.Irreps('1x1e').D_from_angles(alpha, beta, gamma).squeeze(0)\n",
    "rotated_graph.relative_positions = rotated_graph.relative_positions @ position_rotator\n",
    "\n",
    "output_from_rotated = net.forward(graph=rotated_graph)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(5.2387e-10, grad_fn=<MaxBackward1>)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rotated_output - output_from_rotated).max()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T13:00:09.951433900Z",
     "start_time": "2023-08-08T13:00:08.316170700Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
