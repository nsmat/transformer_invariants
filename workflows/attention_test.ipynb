{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "\n",
    "from utils.transforms import EuclideanInformationTransform, OneHot\n",
    "from  models.se3_attention_mechanisms import Se3EquivariantAttentionMechanism\n",
    "\n",
    "import e3nn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Let's test the SE3 equivariant version of the GAT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "g = nx.DiGraph()\n",
    "\n",
    "vertices = (0, 1, 2)\n",
    "edges = [(0, 1),\n",
    "         (1, 2),\n",
    "         (2, 0),\n",
    "         ]\n",
    "\n",
    "z = [0, 1, 2, 1]\n",
    "pos = [(0.,   0.,  0.),\n",
    "       (-1., -1., -1.),\n",
    "       (1.,   1.,  1.),\n",
    "       (2.,   2.,  2.),\n",
    "     ]\n",
    "\n",
    "features = {i: {'z': z[i], 'pos': pos[i]} for i in vertices }\n",
    "\n",
    "for v in vertices:\n",
    "    g.add_node(v)\n",
    "\n",
    "for e in edges:\n",
    "    g.add_edge(*e)\n",
    "\n",
    "nx.set_node_attributes(g, features)\n",
    "\n",
    "graph = tg.utils.from_networkx(g)\n",
    "\n",
    "euc_transform = EuclideanInformationTransform()\n",
    "one_hot_transform = OneHot('z', 'z')\n",
    "transform = tg.transforms.Compose([euc_transform, one_hot_transform])\n",
    "\n",
    "graph = transform(graph)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niksm\\Documents\\CodeForUni\\venvs\\transformer_invariants\\lib\\site-packages\\torch_geometric\\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = tg.data.DataLoader([graph, graph.clone()], batch_size=1)\n",
    "for batch in test_dataloader:\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niksm\\Documents\\CodeForUni\\venvs\\transformer_invariants\\lib\\site-packages\\torch\\jit\\_check.py:181: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\"The TorchScript type system doesn't support \"\n"
     ]
    }
   ],
   "source": [
    "feature_irreps = e3nn.o3.Irreps(\"10x0e + 10x1e + 10x2e\")\n",
    "geometric_irreps = e3nn.o3.Irreps(\"3x0e+3x1e+3x2e\")\n",
    "output_irreps = e3nn.o3.Irreps(\"10x0e + 10x1e + 10x2e\")\n",
    "internal_key_query_irreps = e3nn.o3.Irreps(\"5x0e + 5x1e + 5x2e\")\n",
    "\n",
    "\n",
    "net = Se3EquivariantAttentionMechanism(\n",
    "    feature_irreps=feature_irreps,\n",
    "    geometric_irreps=geometric_irreps,\n",
    "    value_out_irreps=output_irreps,\n",
    "    key_and_query_out_irreps=internal_key_query_irreps,\n",
    "    radial_network_hidden_units=16\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "embed = torch.nn.Linear(batch.z.shape[1], feature_irreps.dim)\n",
    "features = embed(batch.z.float())\n",
    "edge_harmonics = e3nn.o3.spherical_harmonics(geometric_irreps,\n",
    "                                             batch.relative_positions,\n",
    "                                             normalize=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"<eval_with_key>.25\", line 15, in forward\n    getitem_2 = getattr_3[slice(None, -1, None)];  getattr_3 = None\n    expand_2 = empty.expand(getitem_2);  empty = getitem_2 = None\n    broadcast_tensors = torch.functional.broadcast_tensors(expand, expand_1, expand_2);  expand = expand_1 = expand_2 = None\n                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n    getitem_3 = broadcast_tensors[0];  broadcast_tensors = None\n    getattr_4 = getitem_3.shape;  getitem_3 = None\nRuntimeError: The size of tensor a (6) must match the size of tensor b (3) at non-singleton dimension 0\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mnet\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m           \u001B[49m\u001B[43mfeatures\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m           \u001B[49m\u001B[43medge_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_harmonics\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m           \u001B[49m\u001B[43mdistances\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistances\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m                                         \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\CodeForUni\\transformer_invariants\\models\\attention_network.py:52\u001B[0m, in \u001B[0;36mGraphAttentionNetwork.forward\u001B[1;34m(self, edge_index, features, edge_features, **kwargs)\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;66;03m# We add self loops to the index _after_ alphas are computed, since we hardcode the alphas for those\u001B[39;00m\n\u001B[0;32m     51\u001B[0m looped_edge_index, _ \u001B[38;5;241m=\u001B[39m tg\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mloop\u001B[38;5;241m.\u001B[39madd_remaining_self_loops(edge_index, num_nodes\u001B[38;5;241m=\u001B[39mfeatures\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m---> 52\u001B[0m v \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mV(looped_edge_index, features, edge_features, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     54\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpropagate(looped_edge_index,\n\u001B[0;32m     55\u001B[0m                          alpha\u001B[38;5;241m=\u001B[39malpha,\n\u001B[0;32m     56\u001B[0m                          v\u001B[38;5;241m=\u001B[39mv\n\u001B[0;32m     57\u001B[0m                          )\n\u001B[0;32m     59\u001B[0m \u001B[38;5;66;03m# Enormous hack - somehow, adding self loops means that we end up with a number of 0 outputs appended\u001B[39;00m\n\u001B[0;32m     60\u001B[0m \u001B[38;5;66;03m# This appears to be a bug in the underlying\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\CodeForUni\\venvs\\transformer_invariants\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\Documents\\CodeForUni\\transformer_invariants\\models\\tensor_field_networks.py:71\u001B[0m, in \u001B[0;36mGraphAdaptedTensorProduct.forward\u001B[1;34m(self, edge_index, features, edge_features, distances)\u001B[0m\n\u001B[0;32m     68\u001B[0m source_features \u001B[38;5;241m=\u001B[39m features[source_indices]\n\u001B[0;32m     70\u001B[0m \u001B[38;5;66;03m# Key queries, represented as a set of edge features\u001B[39;00m\n\u001B[1;32m---> 71\u001B[0m out_uv \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     72\u001B[0m \u001B[43m                         \u001B[49m\u001B[43medge_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     73\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mdistances\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     74\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out_uv\n",
      "File \u001B[1;32m~\\Documents\\CodeForUni\\transformer_invariants\\models\\tensor_field_networks.py:57\u001B[0m, in \u001B[0;36mRadiallyParamaterisedTensorProduct.forward\u001B[1;34m(self, feature_spherical_harmonics, geometric_spherical_harmonics, norm)\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;124;03mApplies a tensor product, paramaterised by the norm, between vectors of spherical\u001B[39;00m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;124;03m    harmonic coefficients representing features, one the one hand, and and\u001B[39;00m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;124;03m    spherical harmonics representing geometric information on the other.\u001B[39;00m\n\u001B[0;32m     54\u001B[0m \n\u001B[0;32m     55\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     56\u001B[0m weights \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mradial_net(norm)  \u001B[38;5;66;03m# Obtain the weights as a function of the norm\u001B[39;00m\n\u001B[1;32m---> 57\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor_product\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeature_spherical_harmonics\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     58\u001B[0m \u001B[43m                             \u001B[49m\u001B[43mgeometric_spherical_harmonics\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     59\u001B[0m \u001B[43m                             \u001B[49m\u001B[43mweights\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "File \u001B[1;32m~\\Documents\\CodeForUni\\venvs\\transformer_invariants\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\Documents\\CodeForUni\\venvs\\transformer_invariants\\lib\\site-packages\\e3nn\\o3\\_tensor_product\\_tensor_product.py:542\u001B[0m, in \u001B[0;36mTensorProduct.forward\u001B[1;34m(self, x, y, weight)\u001B[0m\n\u001B[0;32m    540\u001B[0m \u001B[38;5;66;03m# - PROFILER - with torch.autograd.profiler.record_function(self._profiling_str):\u001B[39;00m\n\u001B[0;32m    541\u001B[0m real_weight \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_weights(weight)\n\u001B[1;32m--> 542\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compiled_main_left_right\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreal_weight\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\CodeForUni\\venvs\\transformer_invariants\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "\u001B[1;31mRuntimeError\u001B[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"<eval_with_key>.25\", line 15, in forward\n    getitem_2 = getattr_3[slice(None, -1, None)];  getattr_3 = None\n    expand_2 = empty.expand(getitem_2);  empty = getitem_2 = None\n    broadcast_tensors = torch.functional.broadcast_tensors(expand, expand_1, expand_2);  expand = expand_1 = expand_2 = None\n                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n    getitem_3 = broadcast_tensors[0];  broadcast_tensors = None\n    getattr_4 = getitem_3.shape;  getitem_3 = None\nRuntimeError: The size of tensor a (6) must match the size of tensor b (3) at non-singleton dimension 0\n"
     ]
    }
   ],
   "source": [
    "net.forward(edge_index=batch.edge_index,\n",
    "           features=features,\n",
    "           edge_features=edge_harmonics,\n",
    "           distances=batch.distances,\n",
    "                                         )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T16:59:04.739184900Z",
     "start_time": "2023-08-07T16:59:02.891363Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "GraphAdaptedTensorProduct(\n  (tensor_product): FullyConnectedTensorProduct(10x0e+10x1e+10x2e x 3x0e+3x1e+3x2e -> 10x0e+10x1e+10x2e | 4500 paths | 4500 weights)\n  (radial_net): RadialWeightFunction(\n    (net): Sequential(\n      (0): Linear(in_features=1, out_features=16, bias=True)\n      (1): SiLU()\n      (2): Linear(in_features=16, out_features=4500, bias=True)\n    )\n  )\n)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.V"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T16:59:08.557587300Z",
     "start_time": "2023-08-07T16:59:08.453860Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
