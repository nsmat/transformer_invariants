{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "\n",
    "from utils.transforms import EuclideanInformationTransform, OneHot\n",
    "from models.tensor_field_networks import RadiallyParamaterisedTensorProduct, QueryNetwork\n",
    "\n",
    "import e3nn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "class GraphAttentionNetwork(tg.nn.MessagePassing):\n",
    "\n",
    "    def __init__(self, K, Q, V):\n",
    "        super().__init__(aggr='add')\n",
    "        self.K = K\n",
    "        self.Q = Q\n",
    "        self.V = V\n",
    "\n",
    "    def compute_alpha(self, edge_index, k_uv, q):\n",
    "        \"\"\"Creates a matrix of alpha values based on keys and queries\"\"\"\n",
    "        alphas = torch.zeros((dots.shape[0], dots.shape[0]))\n",
    "        for node in range(q.shape[0]): # iterate through the nodes\n",
    "            neighbourhood_edge_indices = (edge_index[1,:] == node).nonzero() # Finds the indices of the edges for which this node is a target.\n",
    "            neighbourhood_edge_indices = neighbourhood_edge_indices.flatten()\n",
    "\n",
    "            neighbourhood_k = k_uv[neighbourhood_edge_indices, :] # Get all k in this neighbourhood\n",
    "            q_node = q[node]\n",
    "\n",
    "            neighbourhood_dot = q_node @ neighbourhood_k.T # Matrix multiplication gives dot products\n",
    "            neighbourhood_alphas = torch.nn.functional.softmax(neighbourhood_dot, dim=0)\n",
    "\n",
    "            # Now, use the edges to store the alphas at the correct points\n",
    "            neighbourhood_edges = edge_index[:, neighbourhood_edge_indices]\n",
    "            source_nodes = neighbourhood_edges[0, :]\n",
    "            alphas[node, source_nodes] = neighbourhood_alphas\n",
    "\n",
    "        # Finally, we force an attention coefficient from each node to itself\n",
    "        diagonal_indices = torch.arange(0, alphas.shape[0])\n",
    "        alphas[diagonal_indices, diagonal_indices] = 1.\n",
    "\n",
    "        return alphas\n",
    "\n",
    "\n",
    "    def forward(self, edge_index, features, geometric_information, distances):\n",
    "        k_uv = self.K(edge_index, features, geometric_information, distances)\n",
    "\n",
    "        q = self.Q(features)\n",
    "        alpha = self.compute_alpha(edge_index, k_uv, q)\n",
    "        v = self.V(edge_index, features, geometric_information, distances)\n",
    "\n",
    "        return self.propagate(edge_index, alpha=alpha, v=v)\n",
    "\n",
    "\n",
    "    def message(self, alpha, v_j, edge_index):\n",
    "        \"\"\"\n",
    "        Absolutely horrendous - v_j is the value of each message, and it is\n",
    "        actually a tensor as long as there are edges in the graph.\n",
    "        Thus, we need to reference the edge index and reshape alpha into\n",
    "        a shape that reflects the edge structure.\n",
    "\n",
    "        awful awful awful\n",
    "        \"\"\"\n",
    "\n",
    "        alpha_j = alpha[edge_index[0, :], edge_index[1, :]]\n",
    "        alpha_j = alpha_j.reshape(alpha_j.shape[0], 1)\n",
    "\n",
    "        return alpha_j*v_j"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T10:37:00.122411100Z",
     "start_time": "2023-08-07T10:37:00.105477200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "g = nx.DiGraph()\n",
    "\n",
    "vertices = (0, 1, 2, 3)\n",
    "edges = [(0, 1),\n",
    "         (1, 2),\n",
    "         (2, 0),\n",
    "         (2, 3),\n",
    "         (3, 0)\n",
    "         ]\n",
    "z = [0, 1, 2, 1]\n",
    "pos = [(0.,   0.,  0.),\n",
    "             (-1., -1., -1.),\n",
    "             (1.,   1.,  1.),\n",
    "             (2.,   2.,  2.),\n",
    "             ]\n",
    "\n",
    "features = {i: {'z': z[i], 'pos': pos[i]} for i in vertices }\n",
    "\n",
    "for v in vertices:\n",
    "    g.add_node(v)\n",
    "\n",
    "for e in edges:\n",
    "    g.add_edge(*e)\n",
    "\n",
    "nx.set_node_attributes(g, features)\n",
    "\n",
    "graph = tg.utils.from_networkx(g)\n",
    "\n",
    "euc_transform = EuclideanInformationTransform()\n",
    "one_hot_transform = OneHot('z', 'z')\n",
    "transform = tg.transforms.Compose([euc_transform, one_hot_transform])\n",
    "\n",
    "graph = transform(graph)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niksm\\Documents\\CodeForUni\\venvs\\transformer_invariants\\lib\\site-packages\\torch_geometric\\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = tg.data.DataLoader([graph, graph.clone()], batch_size=1)\n",
    "for batch in test_dataloader:\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niksm\\Documents\\CodeForUni\\venvs\\transformer_invariants\\lib\\site-packages\\torch\\jit\\_check.py:181: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\"The TorchScript type system doesn't support \"\n"
     ]
    }
   ],
   "source": [
    "feature_irreps = e3nn.o3.Irreps(\"10x0e + 10x1e + 10x2e\")\n",
    "geometric_irreps = e3nn.o3.Irreps(\"3x0e+3x1e+3x2e\")\n",
    "output_irreps = e3nn.o3.Irreps(\"10x0e + 10x1e + 10x2e\")\n",
    "internal_key_query_irreps = e3nn.o3.Irreps(\"5x0e + 5x1e + 5x2e\")\n",
    "\n",
    "K = RadiallyParamaterisedTensorProduct(feature_irreps,\n",
    "                                      geometric_irreps,\n",
    "                                      internal_key_query_irreps,\n",
    "                                      radial_hidden_units=16\n",
    "                                      )\n",
    "Q = QueryNetwork(feature_irreps,\n",
    "                 internal_key_query_irreps)\n",
    "\n",
    "V = RadiallyParamaterisedTensorProduct(feature_irreps,\n",
    "                                       geometric_irreps,\n",
    "                                       output_irreps,\n",
    "                                       radial_hidden_units=16)\n",
    "\n",
    "\n",
    "embed = torch.nn.Linear(batch.z.shape[1], feature_irreps.dim)\n",
    "features = embed(batch.z.float())\n",
    "edge_harmonics = e3nn.o3.spherical_harmonics(geometric_irreps,\n",
    "                                             batch.relative_positions,\n",
    "                                             normalize=False)\n",
    "\n",
    "tt = ToyTransformer(Q=Q, K=K, V=V)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Code to derive the edge features\n",
    "weights = K.radial_net(batch.distances)\n",
    "source_indices = batch.edge_index[0, :]\n",
    "source_features = features[source_indices]\n",
    "\n",
    "k_uv = K.tensor_product(source_features,\n",
    "                 edge_harmonics,\n",
    "                 weights)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(True)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(K(source_features, edge_harmonics, batch.distances) == k_uv).all()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# One row for each node\n",
    "q = Q.forward(features)\n",
    "print(q.shape) # a query vector for each node)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([5, 45])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_uv.shape # A key vector for each edge"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "dots = q @ k_uv.T # Matrix multiplication gives us a number of nodes * number of edges matrix\n",
    "                  # This isn't actually ideal because you waste a few computations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([5, 45])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_uv.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1, 2, 0, 3, 0])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = batch.edge_index[1, :]\n",
    "targets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([5, 45])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_uv.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "edge_index = batch.edge_index\n",
    "\n",
    "alphas = torch.zeros((dots.shape[0], dots.shape[0]))\n",
    "for node in range(dots.shape[0]): # iterate through the nodes\n",
    "    # This gets the indices of the\n",
    "    neighbourhood_edge_indices = (edge_index[1,:] == node).nonzero() # Finds the indices of the edges for which this node is a target.\n",
    "    neighbourhood_edge_indices = neighbourhood_edge_indices.flatten()\n",
    "\n",
    "    neighbourhood_k = k_uv[neighbourhood_edge_indices, :] # Get all k in this neighbourhood\n",
    "    q_node = q[node]\n",
    "\n",
    "    neighbourhood_dot = q_node @ neighbourhood_k.T # Matrix multiplication\n",
    "    neighbourhood_alphas = torch.nn.functional.softmax(neighbourhood_dot, dim=0)\n",
    "\n",
    "    # Now, use the edges to store the alphas at the correct points\n",
    "    neighbourhood_edges = edge_index[:, neighbourhood_edge_indices]\n",
    "    source_nodes = neighbourhood_edges[0, :]\n",
    "    alphas[node, source_nodes] = neighbourhood_alphas\n",
    "\n",
    "# Finally, we force an attention coefficient from each node to itself\n",
    "diagonal_indices = torch.arange(0, alphas.shape[0])\n",
    "alphas[diagonal_indices, diagonal_indices] = 1."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T10:17:01.177677300Z",
     "start_time": "2023-08-07T10:17:01.149091800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.0000, 0.0000, 0.5000, 0.5000],\n        [1.0000, 1.0000, 0.0000, 0.0000],\n        [0.0000, 1.0000, 1.0000, 0.0000],\n        [0.0000, 0.0000, 1.0000, 1.0000]], grad_fn=<IndexPutBackward0>)"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T10:30:37.568594Z",
     "start_time": "2023-08-07T10:30:37.510077100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1.], grad_fn=<SoftmaxBackward0>)"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.softmax(neighbourhood_dot, dim=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T10:16:40.377193200Z",
     "start_time": "2023-08-07T10:16:40.361944100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0., 0., 0., 0.], grad_fn=<DiagBackward0>)"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagonal_indices = torch.arange(0, )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T10:11:20.631966500Z",
     "start_time": "2023-08-07T10:11:20.593514800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 0., 1., 1.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.]])"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T10:09:37.869806400Z",
     "start_time": "2023-08-07T10:09:37.851543300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([45])"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_node.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T10:08:11.083237600Z",
     "start_time": "2023-08-07T10:08:11.059564400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([2, 4])"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbourhood_edge_indices"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T10:08:11.506601200Z",
     "start_time": "2023-08-07T10:08:11.488951900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2, 3],\n        [0, 0]])"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbourhood_edges"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T10:08:11.689750500Z",
     "start_time": "2023-08-07T10:08:11.673716600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "alphas = torch.zeros((dots.shape[0], dots.shape[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T10:08:11.862539100Z",
     "start_time": "2023-08-07T10:08:11.848441600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "alphas[neighbourhood_edges[1, :], neighbourhood_edges[0, :]] = 1.0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T10:08:12.225441100Z",
     "start_time": "2023-08-07T10:08:12.161362700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 0., 1., 1.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.]])"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T10:08:12.979622400Z",
     "start_time": "2023-08-07T10:08:12.958581500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Need to fill these in POST softmax\n",
    "alpha = torch.zeros((q.shape[0], q.shape[0]))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T10:01:00.566191500Z",
     "start_time": "2023-08-07T10:01:00.550875Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expand(torch.FloatTensor{[4, 5]}, size=[]): the number of sizes provided (0) must be greater or equal to the number of dimensions in the tensor (2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m source, target \u001B[38;5;129;01min\u001B[39;00m batch\u001B[38;5;241m.\u001B[39medge_index\u001B[38;5;241m.\u001B[39mT:\n\u001B[1;32m----> 2\u001B[0m     \u001B[43malpha\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msource\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m dots\n",
      "\u001B[1;31mRuntimeError\u001B[0m: expand(torch.FloatTensor{[4, 5]}, size=[]): the number of sizes provided (0) must be greater or equal to the number of dimensions in the tensor (2)"
     ]
    }
   ],
   "source": [
    "for source, target in batch.edge_index.T:\n",
    "    alpha[target, source] = dots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch.edge_index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
