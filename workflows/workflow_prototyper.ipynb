{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import torch_geometric as tg\n",
    "\n",
    "from models.se3_transformer import Se3EquivariantTransformer\n",
    "from utils.load_md17 import load_md17\n",
    "import e3nn\n",
    "\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "\n",
    "from workflows.md17_experiment import MD17TransformerTask\n",
    "import datetime as dt\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T08:49:48.809453400Z",
     "start_time": "2023-08-15T08:49:48.789454700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "### Prototype workflow"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T08:46:33.695316300Z",
     "start_time": "2023-08-15T08:46:33.640310900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niksm\\Documents\\CodeForUni\\venvs\\transformer_invariants\\lib\\site-packages\\torch\\jit\\_check.py:181: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\"The TorchScript type system doesn't support \"\n"
     ]
    }
   ],
   "source": [
    "energy_model = Se3EquivariantTransformer.construct_from_number_of_channels_and_lmax(num_channels=16,\n",
    "                                                                             l_max=2,\n",
    "                                                                             num_features=9, # Derived from dataset\n",
    "                                                                             num_attention_layers=4,\n",
    "                                                                             num_attention_heads=4,\n",
    "                                                                             radial_network_hidden_units=32\n",
    "                                                                             )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T08:46:39.625655Z",
     "start_time": "2023-08-15T08:46:33.696824900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "batch_size=2\n",
    "radius=2\n",
    "\n",
    "data = load_md17(dataset_name='aspirin CCSD', dataset_dir='../real_datasets', radius=radius)\n",
    "\n",
    "train_dataloader = tg.loader.DataLoader(data['train'], batch_size=batch_size, shuffle=True)\n",
    "validation_dataloader = tg.loader.DataLoader(data['validation'], batch_size=batch_size)\n",
    "test_dataloader = tg.loader.DataLoader(data['test'], batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T08:46:39.689295200Z",
     "start_time": "2023-08-15T08:46:39.629658600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([-837711.3125]), tensor(2015.1858))"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MD17TransformerTask.compute_energy_normalisers(dataset=data['train'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T08:46:40.379914900Z",
     "start_time": "2023-08-15T08:46:39.694285200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "timestamp = dt.datetime.now()\n",
    "timestamp = dt.datetime.strftime(timestamp, '%Y-%m-%d_%H-%M')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T08:53:46.817601800Z",
     "start_time": "2023-08-15T08:53:46.786601800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "logger = pl.loggers.CSVLogger(name=\"my_test\", version=timestamp, save_dir='lightning_logs')\n",
    "# Logs are saved to os.path.join(save_dir, name, version).\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=1, logger=logger)\n",
    "task = MD17TransformerTask(energy_model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T08:53:47.037221700Z",
     "start_time": "2023-08-15T08:53:46.962988900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# torch.autograd.set_detect_anomaly(True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T08:53:48.181596500Z",
     "start_time": "2023-08-15T08:53:48.161599900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "C:\\Users\\niksm\\Documents\\CodeForUni\\venvs\\transformer_invariants\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name                | Type                      | Params\n",
      "------------------------------------------------------------------\n",
      "0 | energy_model        | Se3EquivariantTransformer | 672   \n",
      "1 | energy_train_metric | MeanAbsoluteError         | 0     \n",
      "2 | energy_valid_metric | MeanAbsoluteError         | 0     \n",
      "3 | energy_test_metric  | MeanAbsoluteError         | 0     \n",
      "4 | force_train_metric  | MeanAbsoluteError         | 0     \n",
      "5 | force_valid_metric  | MeanAbsoluteError         | 0     \n",
      "6 | force_test_metric   | MeanAbsoluteError         | 0     \n",
      "------------------------------------------------------------------\n",
      "672       Trainable params\n",
      "0         Non-trainable params\n",
      "672       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d5f0a6469e64a0f96ea08c8bda89292"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niksm\\Documents\\CodeForUni\\venvs\\transformer_invariants\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3d9bc494ebbc49e09ed07c8950e5d3c1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niksm\\Documents\\CodeForUni\\venvs\\transformer_invariants\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:52: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(task, train_dataloader, test_dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T08:56:04.615603600Z",
     "start_time": "2023-08-15T08:53:48.359400800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T08:48:54.936294300Z",
     "start_time": "2023-08-15T08:48:54.897292300Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
