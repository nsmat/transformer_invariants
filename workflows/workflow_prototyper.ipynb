{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch_geometric as tg\n",
    "\n",
    "from models.se3_transformer import Se3EquivariantTransformer\n",
    "from utils.load_md17 import load_md17\n",
    "import e3nn\n",
    "\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MD17Transformer(pl.LightningModule):\n",
    "    def __init__(self, model, lr=1e-3, force_loss_weight=500):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "\n",
    "        self.force_loss_weight = force_loss_weight\n",
    "\n",
    "        self.energy_train_metric = torchmetrics.MeanAbsoluteError()\n",
    "        self.energy_valid_metric = torchmetrics.MeanAbsoluteError()\n",
    "        self.energy_test_metric = torchmetrics.MeanAbsoluteError()\n",
    "        self.force_train_metric = torchmetrics.MeanAbsoluteError()\n",
    "        self.force_valid_metric = torchmetrics.MeanAbsoluteError()\n",
    "        self.force_test_metric = torchmetrics.MeanAbsoluteError()\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_energy_normalisers(dataset):\n",
    "        sum_energies = 0\n",
    "        total_nodes = 0\n",
    "        force_scales = 0\n",
    "\n",
    "        for graph in dataset:\n",
    "            total_nodes += graph.num_nodes\n",
    "            sum_energies += graph.energy\n",
    "            force_scales += torch.linalg.vector_norm(graph.force, dim=1).sum()\n",
    "\n",
    "        mean = sum_energies / total_nodes\n",
    "        std = force_scales/total_nodes\n",
    "\n",
    "        return mean, std\n",
    "\n",
    "    def forward(self, graph):\n",
    "        graph.pos = torch.autograd.Variable(graph.pos, requires_grad=True)\n",
    "        predicted_energy = self.model(graph)\n",
    "        predicted_force = -1 * torch.autograd.grad(predicted_energy,\n",
    "                                                   graph.pos,\n",
    "                                                   grad_outputs=torch.ones_like(predicted_energy),\n",
    "                                                   create_graph=True,\n",
    "                                                   retain_graph=True,\n",
    "                                                   )\n",
    "\n",
    "        predicted_force = predicted_force[0]\n",
    "        predicted_energy = predicted_energy.squeeze(-1)\n",
    "\n",
    "        return predicted_energy, predicted_force\n",
    "\n",
    "    def energy_and_force_loss(self, graph, energy, force):\n",
    "        energy_loss = torch.nn.functional.mse_loss(energy, graph.energy)\n",
    "        force_loss = torch.nn.functional.mse_loss(force, graph.force)\n",
    "        loss = energy_loss + self.force_loss_weight*force_loss\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, graph):\n",
    "        energy, force = self(graph)\n",
    "        loss = self.energy_and_force_loss(graph, energy, force)\n",
    "        self.energy_train_metric(energy, graph.energy)\n",
    "        self.force_train_metric(force, graph.force)\n",
    "\n",
    "        cur_lr = self.trainer.optimizers[0].param_groups[0][\"lr\"]\n",
    "        self.log(\"lr\", cur_lr, prog_bar=True, on_step=True)\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        self.log(\"Energy train MAE\", self.energy_train_metric, prog_bar=True)\n",
    "        self.log(\"Force train MAE\", self.force_train_metric, prog_bar=True)\n",
    "\n",
    "    @torch.inference_mode(False)\n",
    "    def validation_step(self, graph, batch_idx):\n",
    "        energy, force = self(graph)\n",
    "        self.energy_valid_metric(energy * self.scale + self.shift, graph.energy)\n",
    "        self.force_valid_metric(force * self.scale, graph.force)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        self.log(\"Energy valid MAE\", self.energy_valid_metric, prog_bar=True)\n",
    "        self.log(\"Force valid MAE\", self.force_valid_metric, prog_bar=True)\n",
    "\n",
    "    def test_step(self, graph, batch_idx):\n",
    "        energy, force = self.forward(graph)\n",
    "        self.energy_test_metric(energy, graph.energy)\n",
    "        self.force_test_metric(force, graph.force)\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        self.log(\"Energy test MAE\", self.energy_test_metric, prog_bar=True)\n",
    "        self.log(\"Force test MAE\", self.force_test_metric, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "        num_steps = self.trainer.estimated_stepping_batches\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_steps)\n",
    "\n",
    "        lr_scheduler_config = {\n",
    "            \"scheduler\": scheduler,\n",
    "            \"interval\": \"step\",\n",
    "            \"frequency\": 1,\n",
    "        }\n",
    "        return [optimizer], [lr_scheduler_config]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Prototype workflow"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Se3EquivariantTransformer.construct_from_number_of_channels_and_lmax(num_channels=8,\n",
    "                                                                             l_max=2,\n",
    "                                                                             num_features=1,\n",
    "                                                                             num_attention_layers=4,\n",
    "                                                                             num_attention_heads=4,\n",
    "                                                                             radial_network_hidden_units=32\n",
    "                                                                             )"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = load_md17(dataset_name='aspirin CCSD', dataset_dir='../real_datasets', radius=2)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['train']"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
