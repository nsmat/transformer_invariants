{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch_geometric as tg\n",
    "\n",
    "from models.se3_transformer import Se3EquivariantTransformer, SE3EquivariantTransformerInverseRadiusSquared, SE3EquivariantTransformerMixedHeads\n",
    "from utils.load_md17 import load_md17\n",
    "import e3nn\n",
    "\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "\n",
    "from workflows.md17_experiment import MD17TransformerTask\n",
    "import datetime as dt\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T15:23:09.157584600Z",
     "start_time": "2023-08-15T15:23:03.988292100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niksm\\Documents\\CodeForUni\\venvs\\transformer_invariants\\lib\\site-packages\\torch\\jit\\_check.py:181: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\"The TorchScript type system doesn't support \"\n"
     ]
    }
   ],
   "source": [
    "b = {'0': 'normal',\n",
    "     '1': 'inverse'\n",
    "     }\n",
    "a = SE3EquivariantTransformerMixedHeads.construct_from_number_of_channels_and_lmax(num_channels=16,\n",
    "                                                                             l_max=2,\n",
    "                                                                             num_features=9, # Derived from dataset\n",
    "                                                                             num_attention_layers=4,\n",
    "                                                                             num_attention_heads=4,\n",
    "                                                                             radial_network_hidden_units=32,\n",
    "                                                                             invariant_dictionary=b\n",
    "                                                                                   )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T15:23:14.650188Z",
     "start_time": "2023-08-15T15:23:09.157584600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Prototype workflow"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "energy_model = Se3EquivariantTransformer.construct_from_number_of_channels_and_lmax(num_channels=16,\n",
    "                                                                             l_max=2,\n",
    "                                                                             num_features=9, # Derived from dataset\n",
    "                                                                             num_attention_layers=4,\n",
    "                                                                             num_attention_heads=4,\n",
    "                                                                             radial_network_hidden_units=32\n",
    "                                                                             )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size=2\n",
    "radius=2\n",
    "\n",
    "data = load_md17(dataset_name='aspirin CCSD', dataset_dir='../real_datasets', radius=radius)\n",
    "\n",
    "train_dataloader = tg.loader.DataLoader(data['train'], batch_size=batch_size, shuffle=True)\n",
    "validation_dataloader = tg.loader.DataLoader(data['validation'], batch_size=batch_size)\n",
    "test_dataloader = tg.loader.DataLoader(data['test'], batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MD17TransformerTask.compute_energy_normalisers(dataset=data['train'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "timestamp = dt.datetime.now()\n",
    "timestamp = dt.datetime.strftime(timestamp, '%Y-%m-%d_%H-%M')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logger = pl.loggers.CSVLogger(name=\"my_test\", version=timestamp, save_dir='lightning_logs')\n",
    "# Logs are saved to os.path.join(save_dir, name, version).\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=1, logger=logger)\n",
    "task = MD17TransformerTask(energy_model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# torch.autograd.set_detect_anomaly(True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.fit(task, train_dataloader, test_dataloader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for b in train_dataloader:\n",
    "    b = b.clone()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "construct_from_number_of_channels_and_lmax() got an unexpected keyword argument 'invariant_dictionary'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m b \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m0\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnormal\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m      2\u001B[0m      \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minverse\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      3\u001B[0m      }\n\u001B[1;32m----> 4\u001B[0m a \u001B[38;5;241m=\u001B[39m \u001B[43mSE3EquivariantTransformerMixedHeads\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconstruct_from_number_of_channels_and_lmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_channels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m16\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m                                                                             \u001B[49m\u001B[43ml_max\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m                                                                             \u001B[49m\u001B[43mnum_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m9\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# Derived from dataset\u001B[39;49;00m\n\u001B[0;32m      7\u001B[0m \u001B[43m                                                                             \u001B[49m\u001B[43mnum_attention_layers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m                                                                             \u001B[49m\u001B[43mnum_attention_heads\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m                                                                             \u001B[49m\u001B[43mradial_network_hidden_units\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m                                                                             \u001B[49m\u001B[43minvariant_dictionary\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mb\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m                                                                                   \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: construct_from_number_of_channels_and_lmax() got an unexpected keyword argument 'invariant_dictionary'"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T15:22:47.541046Z",
     "start_time": "2023-08-15T15:22:47.495654200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
